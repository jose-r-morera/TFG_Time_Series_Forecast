# Sistema de Predicci√≥n Meteorol√≥gica de Canarias

Este proyecto full-stack permite la visualizaci√≥n y an√°lisis de datos meteorol√≥gicos obtenidos de estaciones distribuidas en las Islas Canarias. Permite adem√°s lanzar predicciones autom√°ticas de corto plazo mediante un modelo secuencial LSTM previamente entrenado, que se ejecuta de forma as√≠ncrona para no bloquear la experiencia del usuario y permitir un cierto nivel de paralelismo.

El sistema est√° dividido en dos partes: un frontend interactivo desarrollado con Next.js y React, y un backend en FastAPI que gestiona tareas con Celery y Redis.

---

## üìÇ Estructura General del Proyecto

### Frontend (Next.js + React)

El frontend est√° dise√±ado como una SPA (Single Page Application) que permite seleccionar estaciones meteorol√≥gicas, consultar gr√°ficas de sensores y lanzar peticiones de predicci√≥n.

**Caracter√≠sticas principales:**

* Selector de estaciones agrupadas por ubicaci√≥n.
* Visualizaci√≥n de sensores disponibles por estaci√≥n.
* Indicadores visuales del estado de la predicci√≥n (cargando, fallida, completada).
* Componente visual de progreso y gesti√≥n de los estados erroneos.

**Componentes principales del aplicativo:**

| Archivo                         | Descripci√≥n                                                                                                  |
| ------------------------------- | ------------------------------------------------------------------------------------------------------------ |
| `weather-station-dashboard.tsx` | Componente ra√≠z: gesti√≥n de estado global, selecci√≥n, carga de datos, renderizado de gr√°ficas y predicciones |
| `station-selector.tsx`          | Selector de estaciones meteorol√≥gicas ordenadas por ubicaci√≥n geogr√°fica                                     |
| `sensor-chart.tsx`              | Renderizado de gr√°ficas con datos hist√≥ricos y resultados de predicci√≥n                                      |
| `prediction-status.tsx`         | Indicador de estado para tareas de predicci√≥n activas o completadas                                          |
| `loading-indicator.tsx`         | Componente de carga y visualizaci√≥n del progreso de carga                                                    |
| `no-data-message.tsx`           | Mensaje mostrado cuando no hay observaciones disponibles                                                     |
| `stylish-header.tsx`            | Cabecera con navegaci√≥n y selector de estaci√≥n                                                               |
| `station-info.tsx`              | Informaci√≥n detallada de la estaci√≥n seleccionada                                                            |

---

### Backend (FastAPI + Celery)

El backend expone una API REST encargada de gestionar las solicitudes de predicci√≥n, transformar los datos recibidos, generar las entradas necesarias para el modelo y coordinar su ejecuci√≥n.

**Endpoints disponibles:**

* `POST /predict`: Recibe datos estructurados de una estaci√≥n con observaciones recientes, genera el tensor de entrada y encola una tarea en Celery para su predicci√≥n.
* `GET /predict/{job_id}`: Permite consultar el estado en el que se encuentra la predicci√≥n y, en el caso de que este disponible el resultado correspondiente al `job_id` proporcionado.

**Procesamiento interno:**

* Extracci√≥n de caracter√≠sticas temporales (senos y cosenos del ciclo diario y anual).
* Conversi√≥n de los datos recibidos a tensores NumPy de dimensi√≥n `[1, T, F]`, donde `T=??` y `F=7` (4 features temporales + 3 sensores).
* Predicci√≥n mediante un modelo LSTM entrenado, cuyos pesos se cargan en la inicializaci√≥n del worker.

**Worker Celery:**

* El worker se encarga de ejecutar las predicciones de forma independiente al servidor web.
* Carga el modelo desde `weights/????` en el arranque.
* Usa Redis como broker de tareas y almacenamiento de resultados.

---

## üöÄ Flujo de Predicci√≥n

1. El usuario selecciona una estaci√≥n y lanza la predicci√≥n para un sensor.
2. El frontend recoge los datos de observaci√≥n de los √∫ltimos 48 intervalos horarios.
3. El paquete de datos se estructura y se env√≠a al backend v√≠a `POST /predict`.
4. FastAPI valida, transforma y encola la tarea en Celery.
5. Celery ejecuta el modelo LSTM y guarda el resultado.
6. El frontend consulta peri√≥dicamente `GET /predict/{job_id}` hasta obtener el resultado.
7. Las predicciones se visualizan sobre las gr√°ficas originales del sensor.

---

## üöö Docker Compose

```yaml
services:
  frontend:
    build: ./portal_inferencia
    ports: ["3000:3000"]

  backend:
    build: ./backend_api
    ports: ["8000:8000"]
    environment:
      - REDIS_HOST=redis
      - REDIS_PORT=6379

  celery:
    build: ./backend_api
    command: celery -A celery_worker worker --loglevel=info
    depends_on: [redis]
    environment:
      - REDIS_HOST=redis
      - REDIS_PORT=6379

  redis:
    image: redis:latest
```

---

## üîß Librer√≠a `/lib`

Los componentes listados en el front hacen uso de los siguientes modulos complementarios desarrollados. 

| Archivo                 | Prop√≥sito                                                                                |
| ----------------------- | ---------------------------------------------------------------------------------------- |
| `api.ts`                | Abstracci√≥n de llamadas a la API de Grafcan con manejo de errores                        |
| `chart-setup.ts`        | Estilos globales, configuraciones y ejes para Chart.js                                   |
| `chart-utils.ts`        | L√≥gica para tooltips, leyendas y formato din√°mico de etiquetas                           |
| `data-processing.ts`    | Agregaci√≥n de observaciones a nivel horario, c√°lculo de medias y estructuras de entrada  |
| `prediction-service.ts` | Comunicaci√≥n directa con el backend: `POST /predict` y polling a `GET /predict/{job_id}` |
| `types.ts`              | Definiciones de tipos TypeScript para entidades: estaciones, sensores, observaciones     |
| `utils.ts`              | Funciones utilitarias comunes como formateo de fechas y etiquetas                        |

---

## üìä API de Datos en Tiempo Real

* API SensorThings: `https://sensores.grafcan.es/api/v1.0`
* Est√°ndar OGC para observaciones y sensores IoT.
* Acceso autorizado mediante API key: `Authorization: Api-Key <API_KEY>`

---

## üëÅÔ∏è Visualizaci√≥n de Entrada al Modelo

Durante la fase de predicci√≥n, el backend genera las siguientes im√°genes para depuraci√≥n, donde cada imagen representa la evoluci√≥n temporal de uno de los canales de entrada al modelo:

```
debug_inputs/
‚îú‚îÄ‚îÄ <job_id>_channel_1.png  # sin_day
‚îú‚îÄ‚îÄ <job_id>_channel_2.png  # cos_day
‚îú‚îÄ‚îÄ <job_id>_channel_3.png  # sin_week
‚îú‚îÄ‚îÄ <job_id>_channel_4.png  # cos_week
‚îú‚îÄ‚îÄ <job_id>_channel_5.png  # temperatura
‚îú‚îÄ‚îÄ <job_id>_channel_6.png  # humedad
‚îú‚îÄ‚îÄ <job_id>_channel_7.png  # presi√≥n
```

Estas gr√°ficas permiten verificar que la entrada al modelo fue construida correctamente.


---


## Pruebas de carga con Locust
El sistema puede someterse a pruebas de carga usando Locust, una herramienta open-source para simular m√∫ltiples usuarios concurrentes que ejecutan tareas programadas.

* Se pueden lanzar m√∫ltiples tareas que simulan la creaci√≥n de predicciones (POST /predict) y luego realizar consultas peri√≥dicas (GET /predict/{job_id}) para monitorizar su estado.

* Permite medir el rendimiento del sistema, identificar cuellos de botella y verificar la estabilidad bajo carga.


---


## Escalabilidad y futuro
Aunque el despliegue actual es sencillo y con capacidad limitada de paralelizaci√≥n (un √∫nico worker), el dise√±o es completamente escalable:

- Celery permite m√∫ltiples workers, por lo tanto basta con lanzar m√°s r√©plicas del contenedor del worker para aumentar la capacidad de procesamiento.

- Con un orquestador como Docker Swarm o Kubernetes, se puede escalar horizontalmente de forma autom√°tica.

- Se puede implementar un mecanismo sencillo de arbitraje (como balanceo por colas o prioridad por tipo de tarea) si el volumen de predicciones o su latencia aumenta.


---


## üöß Requisitos T√©cnicos

* Docker y Docker Compose (para entorno de ejecuci√≥n completo)
* Node.js >= 18.x (para desarrollo y testing del frontend)
* Python 3.11 con librer√≠as:

  * `fastapi`, `pydantic`, `uvicorn`
  * `celery`, `redis`, `numpy`, `matplotlib`
  * `tensorflow` (versi√≥n compatible con el modelo entrenado)


---

## üìç Autor

Desarrollado por JR.

El proyecto implementa una arquitectura desacoplada, con procesamiento asincr√≥nico, aprendizaje autom√°tico y visualizaci√≥n meteorol√≥gica con APIs est√°ndar abiertas.

